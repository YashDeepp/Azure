{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa22e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.data = {}\n",
    "        for key, value in kwargs.items():\n",
    "            self.data[key] = value\n",
    "    def __getattr__(self, key):\n",
    "        if key not in self.data:\n",
    "            raise AttributeError(\"'HParams' object has no attribute %s\" % key)\n",
    "        return self.data[key]\n",
    "    def set_hparam(self, key, value):\n",
    "        self.data[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5fd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default hyperparameters\n",
    "hparams = HParams(\n",
    "    num_mels=80,  # Number of mel-spectrogram channels and local conditioning dimensionality network\n",
    "    rescale=True,  # Whether to rescale audio prior to preprocessing\n",
    "    rescaling_max=0.9,  # Rescaling value\n",
    "    use_lws=False,\n",
    "    n_fft=800,  # Extra window size is filled with 0 paddings to match this parameter\n",
    "    hop_size=200,  # For 16000Hz, 200 = 12.5 ms (0.0125 * sample_rate)\n",
    "    win_size=800,  # For 16000Hz, 800 = 50 ms (If None, win_size = n_fft) (0.05 * sample_rate)\n",
    "    sample_rate=16000,  # 16000Hz (corresponding to librispeech) (sox --i <filename>)\n",
    "    frame_shift_ms=None,  # Can replace hop_size parameter. (Recommended: 12.5)\n",
    "    # Mel and Linear spectrograms normalization/scaling and clipping\n",
    "    signal_normalization=True,\n",
    "    # Whether to normalize mel spectrograms to some predefined range (following below parameters)\n",
    "    allow_clipping_in_normalization=True,  # Only relevant if mel_normalization = True\n",
    "    symmetric_mels=True,\n",
    "    # Whether to scale the data to be symmetric around 0. (Also multiplies the output range by 2, \n",
    "    # faster and cleaner convergence)\n",
    "    max_abs_value=4.,\n",
    "    preemphasize=True,  # whether to apply filter\n",
    "    preemphasis=0.97,  # filter coefficient.\n",
    "    # Limits\n",
    "    min_level_db=-100,\n",
    "    ref_level_db=20,\n",
    "    fmin=55,\n",
    "    # Set this to 55 if your speaker is male! if female, 95 should help taking off noise. (To \n",
    "    # test depending on dataset. Pitch info: male~[65, 260], female~[100, 525])\n",
    "    fmax=7600,  # To be increased/reduced depending on data.\n",
    "    ###################### Our training parameters #################################\n",
    "    img_size=96,\n",
    "    fps=25,\n",
    "    batch_size=16,\n",
    "    initial_learning_rate=1e-4,\n",
    "    nepochs=20000000000000000,  ### ctrl + c, stop whenever eval loss is consistently greater than train loss for ~10 epochs\n",
    "    num_workers=16,\n",
    "    checkpoint_interval=3000,\n",
    "    eval_interval=3000,\n",
    "    save_optimizer_state=True,\n",
    "    syncnet_wt=0.0, # is initially zero, will be set automatically to 0.03 later. Leads to faster convergence. \n",
    "    syncnet_batch_size=64,\n",
    "    syncnet_lr=1e-4,\n",
    "    syncnet_eval_interval=10000,\n",
    "    syncnet_checkpoint_interval=10000,\n",
    "    disc_wt=0.07,\n",
    "    disc_initial_learning_rate=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18370b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
